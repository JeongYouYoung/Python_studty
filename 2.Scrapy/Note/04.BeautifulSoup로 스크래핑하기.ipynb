{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BeautifulSoup\n",
    "- 간단하게 HTML과 XML에서 정보를 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BeautifulSoup 기본 사용법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "</head>\n",
      "<body>\n",
      "<h1>스크레이핑이란?</h1>\n",
      "<p>웹 페이지를 분석하는 것</p>\n",
      "<p>원하는 부분을 추출하는 것</p>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "# Library\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "\n",
    "# Site Address\n",
    "url = \"https://zeushahn.github.io/Test/python/bs_exam01.html\"\n",
    "\n",
    "# urlOpen\n",
    "res = req.urlopen(url)\n",
    "\n",
    "# BeautifulSoup(한테 일시켜) 으로 분석하기\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1= 스크레이핑이란?\n",
      "p1= 웹 페이지를 분석하는 것\n",
      "p2= 원하는 부분을 추출하는 것\n"
     ]
    }
   ],
   "source": [
    "# 원하는 부분 추출하기\n",
    "h1 = soup.html.body.h1 # html밑에 ,body 밑에 , h1부분!\n",
    "print(\"h1=\", h1.string) #.string -> 태그없애기 문자 구성에따라 달라져서 string 가 안되면 .text로 써봐\n",
    "\n",
    "p1 = soup.html.body.p\n",
    "print(\"p1=\", p1.string) \n",
    "\n",
    "p2 = p1.next_sibling.next_sibling # 같은 레벨의 동등한 위치에 있는 값을 가져옴 next_sibling를 두번 쓰는건 \\n(줄바꿈)떄문에 두번쓰는거\n",
    "print(\"p2=\", p2.string) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# id로 요소 찾는 방법\n",
    "\n",
    ">id가 있으면 id값 부터 찾는게 좋음!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "</head>\n",
      "<body>\n",
      "<h1 id=\"title\">스크레이핑이란?</h1>\n",
      "<p id=\"body\">웹 페이지를 분석하는 것</p>\n",
      "<p>원하는 부분을 추출하는 것</p>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "# Library\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "\n",
    "# Site Address\n",
    "url = \"https://zeushahn.github.io/Test/python/bs_exam02.html\"\n",
    "\n",
    "# urlOpen\n",
    "res = req.urlopen(url)\n",
    "\n",
    "# BeautifulSoup(한테 일시켜) 으로 분석하기\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id 값이 title : 스크레이핑이란?\n",
      "h1 : 스크레이핑이란?\n",
      "id 값이 body : 웹 페이지를 분석하는 것\n"
     ]
    }
   ],
   "source": [
    "title = soup.find(id=\"title\")\n",
    "print(\"id 값이 title :\",title.string)\n",
    "\n",
    "title = soup.find('h1')\n",
    "print(\"h1 :\",title.string)\n",
    "\n",
    "body = soup.find(id=\"body\")\n",
    "print(\"id 값이 body :\",body.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 여러개의 요소 추출하기\n",
    "\n",
    "> 하이퍼링크 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "</head>\n",
      "<body>\n",
      "<ul>\n",
      "<li><a href=\"http://www.naver.com\">naver</a></li>\n",
      "<li><a href=\"http://www.daum.net\">daum</a></li>\n",
      "</ul>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "# Library\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "\n",
    "# Site Address\n",
    "url = \"https://zeushahn.github.io/Test/python/bs_exam03.html\"\n",
    "\n",
    "# urlOpen\n",
    "res = req.urlopen(url)\n",
    "\n",
    "# BeautifulSoup(한테 일시켜) 으로 분석하기\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naver > http://www.naver.com\n",
      "daum > http://www.daum.net\n"
     ]
    }
   ],
   "source": [
    "links = soup.find_all(\"a\")# a태그 안에 있는걸 다 가지고 올꺼야~!\n",
    "# print(links) # List로 들고오네! for문 쓰면 되겠네!\n",
    "\n",
    "for a in links:\n",
    "    # print(a)\n",
    "    text = a.string\n",
    "    href = a.attrs['href']\n",
    "    print(text, \">\", href)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기상청 RSS에서 필요한 정보만 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "\n",
    "# Site Address\n",
    "url = \"http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp?stnId=109\"\n",
    "\n",
    "# urlOpen\n",
    "res = req.urlopen(url)\n",
    "\n",
    "# BeautifulSoup(한테 일시켜) 으로 분석하기\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "#print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (강수) 28일(화) 오전~30일(목) 오전은 흐리고 비가 오겠습니다. \n",
      " (기온) 이번 예보기간 아침 기온은 21~24도로 오늘(24일, 아침최저기온 19~21도)보다 조금 높겠고, 낮 기온은 25~30도로 오늘(낮최고기온 23~28도)보다 조금 높겠습니다. \n",
      " (해상) 서해중부해상의 물결은 28일(화)~29일(수) 오전은 1.5~3.5m로 높게 일겠고, 그 밖의 날은 1.0~3.0m로 일겠습니다.\n",
      "\n",
      "* 이번 예보기간에는 정체전선의 위치에 따라 강수 구역이 변동될 수 있으며, 정체전선의 영향권에서 벗어난 기간에도 대기불안정으로 소나기가 자주 내리는 곳이 있겠으니, \n",
      "  앞으로 발표되는 예보와 기상정보를 참고하기 바랍니다.\n"
     ]
    }
   ],
   "source": [
    "# title과 wf만 가져오겠다\n",
    "# link = soup.find(\"title\").split('<title>')\n",
    "link1 = soup.find(\"wf\").string.replace(\"○\",\"\").replace(\"<br />\",\"\\n\")\n",
    "print(link1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSS 선택자 사용하기\n",
    "- BeautifulSoup는 자바스크립트 라이브러리인 JQuery처럼 CSS선택자를 지정해서 요소 추출 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "</head>\n",
      "<body>\n",
      "<div id=\"meigen\">\n",
      "<h1>위키북스 도서</h1>\n",
      "<ul class=\"items\">\n",
      "<li>유니티 게임 이펙트 입문</li>\n",
      "<li>스위프트로 시작하는 아이폰 앱 개발 교과서</li>\n",
      "<li>모던 웹사이트 디자인의 정석</li>\n",
      "</ul>\n",
      "</div>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "# Library\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "\n",
    "# Site Address\n",
    "url = \"https://zeushahn.github.io/Test/python/bs_exam04.html\"\n",
    "\n",
    "# urlOpen\n",
    "res = req.urlopen(url)\n",
    "\n",
    "# BeautifulSoup(한테 일시켜) 으로 분석하기\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "print(soup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>위키북스 도서</h1>\n"
     ]
    }
   ],
   "source": [
    "# 필요한 부분을 CSS 쿼리로 추출하기 (# : id | . : class | > : 자식 | 빈칸 : 후손)\n",
    "# 소스를 보면 body입장에서 div는 내 자식이고 나머지는 다 후손임\n",
    "# 맨뒤에부터 적는게 제일 편해\n",
    "\n",
    "h1 = soup.select_one(\"#meigen > h1\") # div 아이디는 meigen이고 div의 자식은 h1 이다.\n",
    "print(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<li>유니티 게임 이펙트 입문</li>, <li>스위프트로 시작하는 아이폰 앱 개발 교과서</li>, <li>모던 웹사이트 디자인의 정석</li>]\n"
     ]
    }
   ],
   "source": [
    "li_list = soup.select(\"div#meigen > ul.items > li\") # ul이 여러개인데 각자 class가 있어\n",
    "print(li_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유니티 게임 이펙트 입문\n",
      "스위프트로 시작하는 아이폰 앱 개발 교과서\n",
      "모던 웹사이트 디자인의 정석\n"
     ]
    }
   ],
   "source": [
    "for li in li_list:\n",
    "    print(li.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 네이버 금융에서 환율 정보 추출하기\n",
    "- https://finance.naver.com/marketindex/  \n",
    "- :에서 도구더보기 -> 개발자도구 -> elemnt -> 마우스로 가져올 정보 클릭하고 -> 우클릭 -> copy -> copy selecter\n",
    "### 미국 환율 가져오기\n",
    "- #exchangeList > li.on > a.head.usd > div > span.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "\n",
    "# Site Address\n",
    "url = \"https://finance.naver.com/marketindex/\"\n",
    "\n",
    "# urlOpen\n",
    "res = req.urlopen(url)\n",
    "\n",
    "# BeautifulSoup(한테 일시켜) 으로 분석하기\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "# print(soup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,296.00\n"
     ]
    }
   ],
   "source": [
    "price = soup.select_one(\"#exchangeList > li.on > a.head.usd > div > span.value\").string # ul이 여러개인데 각자 class가 있어\n",
    "print(price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise \n",
    "# 미국, 일본, 유럽엽합, 중국의 환율 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Library\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "\n",
    "# Site Address\n",
    "url = \"https://finance.naver.com/marketindex/\"\n",
    "\n",
    "# urlOpen\n",
    "res = req.urlopen(url)\n",
    "\n",
    "# BeautifulSoup(한테 일시켜) 으로 분석하기\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "#print(soup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,296.00\n",
      "959.40\n",
      "1,365.85\n",
      "193.72\n",
      "135.2000\n",
      "1.0560\n",
      "1.2271\n",
      "103.9500\n",
      "107.62\n",
      "2130.95\n",
      "1827.0\n",
      "75965.57\n"
     ]
    }
   ],
   "source": [
    "# 풀이\n",
    "# 불러와서 공통점을 찾자\n",
    "##exchangeList > li.on > a.head.usd > div > span.value\n",
    "##exchangeList > li.on > a.head.jpy > div > span.value\n",
    "##exchangeList > li.on > a.head.eur > div > span.value\n",
    "#1번 span.value -> div ->\n",
    "price3 = soup.select(\"span.value\")\n",
    "\n",
    "for price in price3:\n",
    "    print(price.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<span class=\"value\">1,296.00</span>, <span class=\"value\">959.40</span>, <span class=\"value\">1,365.85</span>, <span class=\"value\">193.72</span>]\n"
     ]
    }
   ],
   "source": [
    "# 필요한 부분을 CSS 쿼리로 추출하기 (# : id // . : class // > : 자식 //  빈칸 : 후손)\n",
    "price = soup.select(\"#exchangeList span.value\")\n",
    "print(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1,296.00', '959.40', '1,365.85', '193.72']\n"
     ]
    }
   ],
   "source": [
    "# 가져온 값 리스트에 저장하기\n",
    "price_list = []\n",
    "for span in price:\n",
    "    price_list.append(span.text)\n",
    "print(price_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "미국 :   1,296.00\n",
      "일본 :     959.40\n",
      "유럽연합 :   1,365.85\n",
      "중국 :     193.72\n"
     ]
    }
   ],
   "source": [
    "list_world = [\"미국\",\"일본\",\"유럽연합\",\"중국\"]\n",
    "\n",
    "for i in range(len(price_list)):\n",
    "    print(\"%s : %10s\"%(list_world[i],price_list[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h3 class=\"h_lst\"><span class=\"blind\">미국 USD</span></h3>,\n",
       " <h3 class=\"h_lst\"><span class=\"blind\">일본 JPY(100엔)</span></h3>,\n",
       " <h3 class=\"h_lst\"><span class=\"blind\">유럽연합 EUR</span></h3>,\n",
       " <h3 class=\"h_lst\"><span class=\"blind\">중국 CNY</span></h3>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 풀이2) 나라이름 뽑아서 리스트에 넣기/ 환율값 리스트에 저장하기\n",
    "price4 = soup.select(\"#exchangeList > li > a.head > h3\")\n",
    "price4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['미국 USD', '일본 JPY(100엔)', '유럽연합 EUR', '중국 CNY']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_world2 = []\n",
    "for h3 in price4:\n",
    "    list_world2.append(h3.text)\n",
    "list_world2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "미국 USD :   1,296.00\n",
      "일본 JPY(100엔) :     959.40\n",
      "유럽연합 EUR :   1,365.85\n",
      "중국 CNY :     193.72\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(price_list)):\n",
    "    print(\"%s : %10s\"%(list_world2[i],price_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<span class=\"value\">1,296.00</span>, <span class=\"value\">959.40</span>, <span class=\"value\">1,365.85</span>, <span class=\"value\">193.72</span>]\n",
      "[<span class=\"blind\">미국 USD</span>, <span class=\"blind\">일본 JPY(100엔)</span>, <span class=\"blind\">유럽연합 EUR</span>, <span class=\"blind\">중국 CNY</span>]\n",
      "미국 \t:   1,296.00\n",
      "일본 \t:     959.40\n",
      "유럽연합 \t:   1,365.85\n",
      "중국 \t:     193.72\n"
     ]
    }
   ],
   "source": [
    "price_list = soup.select(\"ul#exchangeList  span.value\")\n",
    "print(price_list)\n",
    "nation_list = soup.select(\"ul#exchangeList h3.h_lst  span.blind\")\n",
    "print(nation_list)\n",
    "for i in range(len(price_list)):\n",
    "  print(\"%s \\t:\"%(nation_list[i].string.split()[0]), price_list[i].string.rjust(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제목 글자 가져오기!\n",
    " - https://movie.daum.net/boxoffice/yearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Library\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "\n",
    "# Site Address\n",
    "url = \"https://movie.daum.net/ranking/boxoffice/yearly\"\n",
    "\n",
    "# urlOpen\n",
    "res = req.urlopen(url)\n",
    "\n",
    "# BeautifulSoup(한테 일시켜) 으로 분석하기\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "#print(soup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1 : 스파이더맨: 노 웨이 홈\n",
      "  2 : 모가디슈\n",
      "  3 : 이터널스\n",
      "  4 : 블랙 위도우\n",
      "  5 : 분노의 질주: 더 얼티메이트\n",
      "  6 : 싱크홀\n",
      "  7 : 극장판 귀멸의 칼날: 무한열차편\n",
      "  8 : 베놈 2: 렛 데어 비 카니지\n",
      "  9 : 소울\n",
      " 10 : 크루엘라\n",
      " 11 : 샹치와 텐 링즈의 전설\n",
      " 12 : 인질\n",
      " 13 : 듄\n",
      " 14 : 보이스\n",
      " 15 : 007 노 타임 투 다이\n",
      " 16 : 미나리\n",
      " 17 : 발신제한\n",
      " 18 : 보스 베이비 2\n",
      " 19 : 콰이어트 플레이스 2\n",
      " 20 : 랑종\n",
      " 21 : 유체이탈자\n",
      " 22 : 컨저링3: 악마가 시켰다\n",
      " 23 : 기적\n",
      " 24 : 고질라 VS. 콩\n",
      " 25 : 킹스맨: 퍼스트 에이전트\n",
      " 26 : 엔칸토: 마법의 세계\n",
      " 27 : 연애 빠진 로맨스\n",
      " 28 : 장르만 로맨스\n",
      " 29 : 미션 파서블\n",
      " 30 : 더 수어사이드 스쿼드\n",
      " 31 : 비와 당신의 이야기\n",
      " 32 : 서복\n",
      " 33 : 킬러의 보디가드 2\n",
      " 34 : 루카\n",
      " 35 : 자산어보\n",
      " 36 : 내일의 기억\n",
      " 37 : 라야와 마지막 드래곤\n",
      " 38 : 프리 가이 \n",
      " 39 : 더 스파이\n",
      " 40 : 강릉\n",
      " 41 : 정글 크루즈\n",
      " 42 : 명탐정 코난: 비색의 탄환\n",
      " 43 : 캐시트럭\n",
      " 44 : 크루즈 패밀리: 뉴 에이지\n",
      " 45 : 이스케이프 룸 2: 노 웨이 아웃\n",
      " 46 : 극장판 포켓몬스터: 정글의 아이, 코코\n",
      " 47 : 극장판 짱구는 못말려: 격돌! 낙서왕국과 얼추 네 명의 용사들\n",
      " 48 : 매트릭스: 리저렉션\n",
      " 49 : 방법: 재차의\n",
      " 50 : 새해전야\n"
     ]
    }
   ],
   "source": [
    "#mainContent > div > div.box_boxoffice > ol > li:nth-child(1) > div > div.thumb_cont > strong > a\n",
    "#mainContent > div > div.box_boxoffice > ol > li:nth-child(1) > div > div.thumb_cont > strong > a\n",
    "\n",
    "title = soup.select(\"strong > a\")\n",
    "#print(title)\n",
    "num = 0\n",
    "for a in title:\n",
    "    list = a.string\n",
    "    num += 1 \n",
    "    print(\"%3d : %s\"%(num,list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스파이더맨: 노 웨이 홈\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2F4fc5880afdb5b7c60161f34184e1f466814fec2d\n",
      "모가디슈\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2F232a8d6e902c63036bbe2ae327d57e82585a639f\n",
      "이터널스\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2Ff2d3ee4afbc78b44e34534037e17f7f382e1b65c\n",
      "블랙 위도우\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2Ff39274b0acd76f7c66f0a5fb9e5b7222ed37b373\n",
      "분노의 질주: 더 얼티메이트\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2Faa6aaf313fb192e6f77f5bd4490d5e127d707240\n",
      "싱크홀\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2F446090579974d44551356ce961743e57eaa41bd6\n",
      "극장판 귀멸의 칼날: 무한열차편\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2Fe2733bbc22a93d16bace5658738322df204bbf01\n",
      "베놈 2: 렛 데어 비 카니지\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2F4abb16fd8b2e51e518b7e0165633d4b9602f2495\n",
      "소울\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2F71454256ae63506a7fee5e03cf929b9b65a4f433\n",
      "크루엘라\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2Fa0fa0de4d943ad43edcae85122d8ee7e52ef60ea\n",
      "샹치와 텐 링즈의 전설\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2F5a64941e61f5a3fbcad8ef6bbf7edb073b35c01a\n",
      "인질\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2F5c2c57cab283c1111fd1c5f5f0ac05b9be2780c7\n",
      "듄\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2Fd0235b8e9c0048e4301f8c9c74da929863e33456\n",
      "보이스\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2Fd0643e2cd42252fb6d9018173e867fcd9612c115\n",
      "007 노 타임 투 다이\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2F316e880b27c97eddd0b6f0a42aff0cf1fecd960a\n",
      "미나리\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2Fc23137b8c082f66df707f21c9884ca38a1903efa\n",
      "발신제한\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2F667ec351ca416f265896cf5768e94e65177b4da5\n",
      "보스 베이비 2\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2F9ab1a372dd93ced3c357eabb8e01f3f5d6003267\n",
      "콰이어트 플레이스 2\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2F017ba53fae24f8961d3d15c2998d12b10c99cdf1\n",
      "랑종\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2F88c733527983cbd6ab27e4f5f0673358ecfdf9eb\n",
      "유체이탈자\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2F2eee1b07783f3ae40b0446fdcc73851956299a6a\n",
      "컨저링3: 악마가 시켰다\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2F9d7e759a721b7f67ae5d52c2d1d977855ba276aa\n",
      "기적\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2Ff09b6fed698932a9258208f8cc4d041ac95efbbd\n",
      "고질라 VS. 콩\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2Feb7a298ab409fa3aa5969257fb1116c7baf5306d\n",
      "킹스맨: 퍼스트 에이전트\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2F6b8b6ca0acd78221f254f00954744005c99160fb\n",
      "엔칸토: 마법의 세계\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2F28a2bbf1962b4f0a48c72f49957c5e4604ca9ccc\n",
      "연애 빠진 로맨스\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2Fa0fcbda650c0e964ac945ebbe38c5ec8d2dc55ff\n",
      "장르만 로맨스\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2F7d54d4dec506b1386961fbac801aaff2287d953d\n",
      "미션 파서블\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2Fccd72de0525f9d555fd8b5e07192d51c3f6aef54\n",
      "더 수어사이드 스쿼드\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2F8c183d3a3ac7d926c9aac443a650211a7e5494f4\n",
      "비와 당신의 이야기\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2Fcaf611172ce6313c2122695ca43f4a81c137eb76\n",
      "서복\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2F8bf7128761445af9838d9e01effe996f06cd5700\n",
      "루카\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2Fa31e64220c3196fc3f664dbd520e4cf64a4a91bd\n",
      "자산어보\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2F31048b63f84f0be67c9aae00c107cf0d4ec375fa\n",
      "내일의 기억\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2F7097614d112f21bbf7ca3b59448a506c6f6632e4\n",
      "라야와 마지막 드래곤\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2F75797aeba183748c728cc35682e7db0a0dc191cf\n",
      "프리 가이 \n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2Fb83ce3cb29a492a800a4c18c0c168987ecc21e43\n",
      "더 스파이\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2F1e9fac169c256896fc9c43332cb4a357b3daa863\n",
      "강릉\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2F68abec870c08bd07292a5c057be49158778fe731\n",
      "정글 크루즈\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2Ff489812c2c10a97480b43ce96d2a83626c279282\n",
      "명탐정 코난: 비색의 탄환\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2Fbe93442510f0462a3d1ab67aebf3e8c9d6e1d94e\n",
      "캐시트럭\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2Fbc4f8b3a720cbab4a8961491cdd7cfd9ca9eaa0c\n",
      "크루즈 패밀리: 뉴 에이지\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2F400267dde749251be83558ea489b0440b1579b07\n",
      "이스케이프 룸 2: 노 웨이 아웃\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2F4ec63ea20869c6a243ebbf2756706a022a11dc7d\n",
      "극장판 포켓몬스터: 정글의 아이, 코코\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2Fc607318ce0a60a7d8b8e540ea599f588751df07e\n",
      "극장판 짱구는 못말려: 격돌! 낙서왕국과 얼추 네 명의 용사들\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2F9ab42f8d99b9b6a6bceb169917a3a0c2c222e942\n",
      "매트릭스: 리저렉션\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2Fe4123c31005612fcdb4acaf7182d4397a9673b3f\n",
      "방법: 재차의\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2F076d1c40be99ec226f0b1a8eec8351034d7072f3\n",
      "새해전야\n",
      "https://img1.daumcdn.net/thumb/C408x596/?fname=https%3A%2F%2Ft1.daumcdn.net%2Fmovie%2F2d44e803f67bafec1c7478317cf94db05c450a3c\n"
     ]
    }
   ],
   "source": [
    "#mainContent > div > div.box_boxoffice > ol > li:nth-child(1) > div > div.thumb_item > div.poster_movie > img\n",
    "#mainContent > div > div.box_boxoffice > ol > li:nth-child(2) > div > div.thumb_item > div.poster_movie > img\n",
    "title = soup.select(\"div.poster_movie > img\")\n",
    "#print(title)\n",
    "\n",
    "\n",
    "for src in title:\n",
    "    text = src.attrs['alt']\n",
    "    href = src.attrs['src']\n",
    "   \n",
    "    # print(text)\n",
    "    # print(href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#라이브러리 불러오기\n",
    "import urllib.request as request\n",
    "\n",
    "#다운로드 파일이름 결정\n",
    "for i in range(len(title)):\n",
    "    url = title[i].attrs['src']\n",
    "    saveName = f\"../Data/{title[i].attrs['alt']}.jpeg\"\n",
    "    request.urlretrieve(url, saveName)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
