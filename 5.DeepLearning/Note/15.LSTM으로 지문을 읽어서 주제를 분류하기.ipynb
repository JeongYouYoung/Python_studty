{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dishplace is located in sunnyvale downtown the...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>service can be slower during busy hours but ou...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>portions are huge both french toast and their ...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we started with apps going the chicken and waf...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the biscuits and gravy was too salty two peopl...</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           paragraph category\n",
       "0  dishplace is located in sunnyvale downtown the...     food\n",
       "1  service can be slower during busy hours but ou...     food\n",
       "2  portions are huge both french toast and their ...     food\n",
       "3  we started with apps going the chicken and waf...     food\n",
       "4  the biscuits and gravy was too salty two peopl...     food"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../Data/lstm.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['food', 'sports'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 중복된것을 제거하고 대소문자를 찢어놔야된다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "536"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터에 사용된 중복 없는 전체 단어 갯수를 파악\n",
    "results = set() # 중복 제거 : set()\n",
    "df['paragraph'].str.lower().str.split().apply(results.update)\n",
    "vocab_size = len(results)\n",
    "vocab_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dishplace is located in sunnyvale downtown there is parking around the area but it can be difficult to find during peak business hours my sisters and i came to this place for dinner on a weekday they were really busy so i highly recommended making reservations unless you have the patience to wait',\n",
       " 'service can be slower during busy hours but our waiter was courteous and help gave some great entree recommendations',\n",
       " 'portions are huge both french toast and their various omelettes are really good their french toast is probably 1.5x more than other brunch places great place to visit if you are hungry and dont want to wait 1 hour for a table',\n",
       " 'we started with apps going the chicken and waffle slides and chicken nachos the sliders were amazing and the nachos were good too maybe by themselves the nachos would have scored better but after those sliders they were up against some tough competition',\n",
       " 'the biscuits and gravy was too salty two people in my group had the gravy and all thought it was too salty my hubby ordered a side of double egg and it was served on two small plates who serves eggs to one person on separate plates we commented on that when it was delivered and even the server laughed and said she doesnt know why the kitchen does that presentation of food is important and they really missed on this one']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어를 숫자로 인코딩\n",
    "paragraphs = df['paragraph'].to_list()\n",
    "paragraphs[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "# keras에서 setseed한 것\n",
    "# keras.utils.set_random_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one-hot-encoding[1] : [533, 190, 523, 312, 213, 196, 527, 362, 242, 418, 190, 264, 266, 100, 377, 376, 94, 135, 441] \n",
      "전체 row 갯수 :  20\n"
     ]
    }
   ],
   "source": [
    "# One hot encoding\n",
    "encoded_paragraphs = [keras.preprocessing.text.one_hot(paragraph, vocab_size) for paragraph in paragraphs]\n",
    "print(\"one-hot-encoding[1] :\",encoded_paragraphs[1],\"\\n전체 row 갯수 : \",len(encoded_paragraphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n"
     ]
    }
   ],
   "source": [
    "# 데이터에서 가장 긴 문장의 단어 갯수 확인\n",
    "max_length = 0\n",
    "for row in df['paragraph']:\n",
    "    if len(row.split(\" \")) > max_length:\n",
    "        max_length = len(row.split(\" \"))\n",
    "print(max_length)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[240, 149, 347, ...,   0,   0,   0],\n",
       "       [533, 190, 523, ...,   0,   0,   0],\n",
       "       [188, 338,  49, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [277, 518, 150, ...,   0,   0,   0],\n",
       "       [362, 443, 113, ...,   0,   0,   0],\n",
       "       [141, 446, 443, ...,   0,   0,   0]], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장마다 단어 갯수가 다르므로 sequencce padding을 넣어서 문장의 길이를 동일하게 만듭니다.\n",
    "padded_paragraphs_encoding = keras.preprocessing.sequence.pad_sequences(\n",
    "    encoded_paragraphs, maxlen = max_length, padding='post'\n",
    ")\n",
    "padded_paragraphs_encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류항목(food, sports)를 수치로 변경하기\n",
    "\n",
    "categories = df['category'].to_list()\n",
    "\n",
    "def category_encode(category):\n",
    "    if category == \"food\":\n",
    "        return [1,0]\n",
    "    else:\n",
    "        return [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0],\n",
       " [1, 0],\n",
       " [1, 0],\n",
       " [1, 0],\n",
       " [1, 0],\n",
       " [1, 0],\n",
       " [1, 0],\n",
       " [1, 0],\n",
       " [1, 0],\n",
       " [1, 0],\n",
       " [0, 1]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_category = [category_encode(category) for category in categories]\n",
    "encoded_category[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[240, 149, 347, 417, 83, 491, 107, 149, 232, 223, 443, 154, 362, 43, 190, 523, 429, 311, 166, 213, 190, 441, 527, 310, 280, 266, 76, 446, 311, 504, 79, 150, 261, 489, 529, 142, 248, 135, 251, 196, 488, 76, 412, 503, 369, 425, 243, 292, 460, 443, 413, 311, 344]\n"
     ]
    }
   ],
   "source": [
    "# Feature 확인\n",
    "print(encoded_paragraphs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_paragraphs[19])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 주제를 분류하는 모델 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# 문맥 생성 단계\n",
    "model.add(keras.layers.Embedding(vocab_size, 5, input_length=max_length))\n",
    "# embedding 레이어는 인덱스를 받아 5차원 벡터의 embedding을 출력합니다. \n",
    "# 5차원인 이유는 과거, 과거진행, 과거완료, 현재, 현재진행, 현재완료 ? 아님 5형식?\n",
    "model.add(keras.layers.LSTM(64))\n",
    "# 분류단계\n",
    "model.add(keras.layers.Dense(32, activation='relu')) # LSTM 반값\n",
    "model.add(keras.layers.Dense(2, activation='softmax')) # 문장은 확률값을 구해야하므로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_X = np.array(padded_paragraphs_encoding)\n",
    "train_Y = np.array(encoded_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-29 09:30:39.124626: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 10ms/step - loss: 0.6926 - accuracy: 0.5500\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6926 - accuracy: 0.5500\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6926 - accuracy: 0.5500\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6909 - accuracy: 0.6000\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6906 - accuracy: 0.6000\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6902 - accuracy: 0.6000\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6898 - accuracy: 0.6000\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6886 - accuracy: 0.6000\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6880 - accuracy: 0.6000\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6881 - accuracy: 0.6000\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.6864 - accuracy: 0.6000\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6852 - accuracy: 0.6000\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6840 - accuracy: 0.6000\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6818 - accuracy: 0.6000\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6790 - accuracy: 0.6000\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6738 - accuracy: 0.6000\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6688 - accuracy: 0.6000\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6361 - accuracy: 0.8500\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5871 - accuracy: 0.7500\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5589 - accuracy: 0.7000\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4410 - accuracy: 0.8500\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3702 - accuracy: 0.8500\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4020 - accuracy: 0.8000\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4359 - accuracy: 0.8500\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3670 - accuracy: 0.8500\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2766 - accuracy: 0.9000\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1151 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6493 - accuracy: 0.9000\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0761 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1396 - accuracy: 0.9500\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2435 - accuracy: 0.9000\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2621 - accuracy: 0.9000\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2521 - accuracy: 0.9000\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1379 - accuracy: 0.9500\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0238 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0207 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0171 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0023 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14a17bfa0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터가 많으면 batch_size를 써줘야된다.\n",
    "model.fit(train_X, train_Y, batch_size=10, epochs=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "00c8100a7997e958d8100731b108691612e131425235a19f9419f6b3b0ff44b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
